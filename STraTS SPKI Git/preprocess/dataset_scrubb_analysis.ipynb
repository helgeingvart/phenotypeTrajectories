{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove patients with amount of samples outside of these invervals.\n",
    "MAX_LENGTH_OF_STAY = 60\n",
    "MIN_LENGTH_OF_STAY = 8\n",
    "\n",
    "# Remove patients with samples/day outside of these invervals.\n",
    "HIGH_SAMPLE_FREQUENCY_LIMIT = 24\n",
    "LOW_SAMPLE_FREQUENCY_LIMIT = 1\n",
    "\n",
    "SAVE_DATA = True\n",
    "SAVE_DATA_AS = f'../data/EWS_0122-0423_scrubbed_O{MIN_LENGTH_OF_STAY}U{MAX_LENGTH_OF_STAY}.csv'\n",
    "SAVE_DATA_AS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('../data/EWS_0122-0423_preprocessed.csv').sort_values('PatientID')\n",
    "df_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicated rows, min amount of datapoints, split patients with over 48h between datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len_mean_var(df, column_name):\n",
    "    #Group the DataFrame by the column you are interested in and count the rows in each group\n",
    "    grouped = df.groupby(column_name).size()\n",
    "\n",
    "    #Calculate the mean and standard deviation of the number of rows\n",
    "    mean_count = grouped.mean()\n",
    "    std_count = grouped.std()\n",
    "    num_patients = len(df[column_name].unique())\n",
    "    return num_patients, round(mean_count,1), round(std_count, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrubb = df_orig.drop_duplicates(subset=df_orig.columns.difference(['Index']), inplace=False)\n",
    "print('Original Data')\n",
    "print(f'Number of patients in dataset: {len(df_orig.PatientID.unique())}, rows in original dataset: {len(df_orig)}')\n",
    "\n",
    "# sort the non duplicated data-frame\n",
    "df_scrubb = df_scrubb.sort_values(['PatientID', 'Timestamp'])\n",
    "df_scrubb.Index = np.arange(0,len(df_scrubb))\n",
    "df_scrubb.set_index(np.arange(0,len(df_scrubb)), inplace=True)\n",
    "\n",
    "\n",
    "stats = get_len_mean_var(df_orig, \"PatientID\")\n",
    "print(f'Stats for of dataset, Patients: {stats[0]}, Mean datapoints: {stats[1]} and Standard deviation datapoints: {stats[2]}')\n",
    "\n",
    "print('\\nDuplicated rows')\n",
    "print(f'Number of duplicated rows: {len(df_orig)-len(df_scrubb)}. That is {round(100-len(df_scrubb)/len(df_orig)*100, 2)}% of the dataset rows.')\n",
    "stats = get_len_mean_var(df_scrubb, \"PatientID\")\n",
    "print(f'Stats for of dataset, Patients: {stats[0]}, Mean datapoints: {stats[1]} and Standard deviation datapoints: {stats[2]}')\n",
    "\n",
    "df_orig.sort_values('Gender')\n",
    "print(\"Removing duplicated rows, ignoring gender - assume gender don't change during stay\")\n",
    "print(f\"Gender distribution before:\\n {df_scrubb.drop_duplicates(subset=['PatientID', 'Gender'])['Gender'].value_counts()}\")\n",
    "df_scrubb = df_orig.sort_values('Gender').drop_duplicates(subset=df_orig.columns.difference(['Index', 'Gender']), keep='first', inplace=False).sort_values('Index')\n",
    "print(f'Number of duplicated rows: {len(df_orig)-len(df_scrubb)}. That is {round(100-len(df_scrubb)/len(df_orig)*100, 2)}% of the dataset rows.')\n",
    "print(f\"Gender distribution after:\\n {df_scrubb.drop_duplicates(subset=['PatientID', 'Gender'])['Gender'].value_counts()}\")\n",
    "stats = get_len_mean_var(df_scrubb, \"PatientID\")\n",
    "print(f'Stats for of dataset, Patients: {stats[0]}, Mean datapoints: {stats[1]} and Standard deviation datapoints: {stats[2]}')\n",
    "df_orig_no_dup = df_scrubb.copy()\n",
    "\n",
    "# remove patients with less than MIN_LENGTH_OF_STAY amount of timesteps\n",
    "val_count = df_scrubb.PatientID.value_counts()\n",
    "df_scrubb = df_scrubb[df_scrubb.PatientID.isin(val_count[val_count >= MIN_LENGTH_OF_STAY].index)]\n",
    "print(f\"\\nRemoving patients with few datapoints (under {MIN_LENGTH_OF_STAY} datapoints). \")\n",
    "print(f'Number of rows from patients with under {MIN_LENGTH_OF_STAY} datapoints: {sum(val_count[val_count < MIN_LENGTH_OF_STAY])}. That is {round(sum(val_count[val_count < MIN_LENGTH_OF_STAY])/len(df_orig)*100, 2)}% of the dataset rows.')\n",
    "stats = get_len_mean_var(df_scrubb, \"PatientID\")\n",
    "print(f'Stats for of dataset, Patients: {stats[0]}, Mean datapoints: {stats[1]} and Standard deviation datapoints: {stats[2]}')\n",
    "\n",
    "# check for patients with multiple obeservations on the same timestep\n",
    "double_data = []\n",
    "for patID in df_scrubb.PatientID.unique():\n",
    "    df_patID = df_scrubb[df_scrubb.PatientID==patID].copy()\n",
    "    if len(df_patID) != len(df_patID.Timestamp.unique()):\n",
    "        double_data.append(df_patID.PatientID.iloc[0])\n",
    "to_remove = df_scrubb[df_scrubb.PatientID.isin(double_data)]\n",
    "# checked manually that all duplicates manually, first notation had 1 value that differed, looking like a typo. \n",
    "# removing first of duplicated values.\n",
    "to_remove = to_remove[to_remove.duplicated(subset=['Timestamp'], keep='first')]\n",
    "df_scrubb.drop(to_remove.Index, inplace=True)\n",
    "print(f'Found {len(to_remove)} paris of with the same patient ID and timestamp, removing outlier from each pair from the dataset.')\n",
    " ### Splitting patients with mutiple visits and checking for constant gender.\n",
    "# split patients that have multiple visits\n",
    "min_hours_to_split = 48\n",
    "# df = df[df.Index<2000]\n",
    "i=0\n",
    "j=0\n",
    "result = pd.DataFrame()\n",
    "\n",
    "# set all None like value to 'None' for Gender feature\n",
    "df_scrubb.Gender = df_scrubb.Gender.astype('str')\n",
    "df_scrubb.loc[df_scrubb.Gender=='nan', 'Gender'] = 'None'\n",
    "df_scrubb.loc[df_scrubb.Gender=='U', 'Gender'] = 'None'\n",
    "\n",
    "print(f\"Gender distribution before:\\n {df_scrubb.drop_duplicates(subset=['PatientID', 'Gender'])['Gender'].value_counts()}\")\n",
    "print(f'\\nLooping through {len(df_scrubb.PatientID.unique())} patients...')\n",
    "print(f\"Splitting patients with more than {min_hours_to_split} hours between data points.\")\n",
    "for patID in tqdm(df_scrubb.PatientID.unique()):\n",
    "    df_patID = df_scrubb[df_scrubb.PatientID==patID].copy()\n",
    "    \n",
    "    # checking for change in gender during the stay, set genter to the value that is not None\n",
    "    if len(df_scrubb[df_scrubb.PatientID==patID].Gender.unique())>1:\n",
    "        mask = df_scrubb[df_scrubb.PatientID==patID].Gender.unique() != 'None'\n",
    "        df_scrubb.loc[df_scrubb.PatientID==patID,'Gender'] =df_scrubb[df_scrubb.PatientID==patID].Gender.unique()[mask][0] \n",
    "\n",
    "    # checking for patients with split in datapoints time.\n",
    "    time_in = min(df_patID.Timestamp)\n",
    "    time_in_care = (df_patID['Timestamp'] - time_in) / (1000 * 3600)\n",
    "    df_patID[df_patID.columns[df_patID.columns.get_loc('Timestamp')]] = time_in_care\n",
    "    df_patID['Difference'] = df_patID['Timestamp'].diff()\n",
    "\n",
    "    df_scrubb.loc[df_patID.Index, 'Time_in_care'] = time_in_care\n",
    "    \n",
    "    if any(df_patID[df_patID['Difference'].notna()]['Difference'].abs() > min_hours_to_split):\n",
    "        i+=1\n",
    "        pat_to_split = df_patID[df_patID['Difference'].abs() > min_hours_to_split]\n",
    "        for k in range(len(pat_to_split)):\n",
    "            j+=1\n",
    "            # split patients that has long gaps between datapoints, PatientID + 10 000 000.\n",
    "            df_scrubb.loc[(df_scrubb.PatientID == pat_to_split.PatientID.iloc[k]) & (df_scrubb.Index < pat_to_split.Index.iloc[k]), 'PatientID'] += 10000000*(k+1)\n",
    "\n",
    "        result = pd.concat([result, pat_to_split])\n",
    "print(f\"Gender distribution after:\\n {df_scrubb.drop_duplicates(subset=['PatientID', 'Gender'])['Gender'].value_counts()}\")\n",
    "\n",
    "\n",
    "val_count = df_scrubb.PatientID.value_counts()\n",
    "print(f'\\nFound {i} amount of patients with gap longer than {min_hours_to_split} hours in their stay. Splitting them into different PatientID, {j} new patients.')\n",
    "stats = get_len_mean_var(df_scrubb, \"PatientID\")\n",
    "print(f'Stats for of dataset, Patients: {stats[0]}, Mean datapoints: {stats[1]} and Standard deviation  datapoints: {stats[2]}')\n",
    "\n",
    "print(f\"\\nFound {len(val_count[val_count < MIN_LENGTH_OF_STAY])} amount of short stays (under {MIN_LENGTH_OF_STAY} datapoints) after splitting, removing them. \" \n",
    "      f\"That is {round(sum(val_count[val_count < MIN_LENGTH_OF_STAY])/len(df_orig)*100, 2)}% of the dataset rows.\")\n",
    "df_scrubb = df_scrubb[df_scrubb.PatientID.isin(val_count[val_count >= MIN_LENGTH_OF_STAY].index)] # remove splits with less than MIN_LENGTH_OF_STAY datapoints. \n",
    "stats = get_len_mean_var(df_scrubb, \"PatientID\")\n",
    "print(f'Stats for of dataset, Patients: {stats[0]}, Mean datapoints: {stats[1]} and Standard deviation  datapoints: {stats[2]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change ward ID to combinde wards with similar patients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping based on info from St√•le Nymo: (NB: TOOK INTO CONSIDERATION ADDED INFO FROM MAIL\n",
    "# 1: Psychiatry: 106, 105, 107, 70, 72\n",
    "# 2: Medicine: 84, 83, 110, 64, 65, 85\n",
    "# 3: Surgical AND Ortopedics (75): 67, 91, 114, 92, 75\n",
    "# 5: Neurology: 79\n",
    "# 6: ICU: 96, 82\n",
    "# 7: Obst / Gyn: 97, 117\n",
    "# 8: Observation unit: 108\n",
    "# 9: Unknown\n",
    "\n",
    "def getWard(w):\n",
    "    if w == 106 or w == 105 or w == 107 or w == 72 or w == 70:\n",
    "        return 1\n",
    "    elif w == 83 or w == 84 or w == 85 or w == 64 or w == 65 or w == 110:\n",
    "        return 2\n",
    "    elif w == 67 or w == 91 or w == 92 or w == 114 or w == 75:\n",
    "        return 3\n",
    "    elif w == 79:\n",
    "        return 5\n",
    "    elif w == 96 or w == 82:\n",
    "        return 6\n",
    "    elif w == 97 or w == 117:\n",
    "       return 7\n",
    "    elif w == 108:\n",
    "        return 8\n",
    "    else:\n",
    "        return 9\n",
    "\n",
    "df_scrubb['WardID'] = df_scrubb['WardID'].apply(getWard)\n",
    "print('Unique Ward ID and counts', np.unique(df_scrubb.WardID, return_counts=True))\n",
    "df_scrubb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats for original Data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat, count = np.unique(df_orig_no_dup.PatientID, return_counts=True)\n",
    "\n",
    "print(f'Amount of patients: {len(np.unique(df_orig_no_dup.PatientID))}')\n",
    "print(f'Amount less or equal than {MIN_LENGTH_OF_STAY}: {len(count[count < MIN_LENGTH_OF_STAY])}')\n",
    "print(f'Amount more than {MIN_LENGTH_OF_STAY}: {len(count[count >= MIN_LENGTH_OF_STAY])}')\n",
    "print(f'Amount more than {MAX_LENGTH_OF_STAY}: {len(count[count >= MAX_LENGTH_OF_STAY])}')\n",
    "\n",
    "# Plotting histogram\n",
    "plt.hist(x=count[(count <= MAX_LENGTH_OF_STAY) & (count >= MIN_LENGTH_OF_STAY)], bins=int((MAX_LENGTH_OF_STAY-MIN_LENGTH_OF_STAY) / 3), color='blue', label=f'{MIN_LENGTH_OF_STAY} or more data samples')\n",
    "plt.hist(x=count[count < MIN_LENGTH_OF_STAY], bins=int((MIN_LENGTH_OF_STAY) / 3), color='orange', label=f'Under {MIN_LENGTH_OF_STAY} data samples')\n",
    "plt.hist(x=count[count < 4], bins=int((4) / 3), color='red', label=f'Under {4} data samples')\n",
    "plt.xlabel('Data samples for patients', fontsize=18, weight='bold')\n",
    "plt.ylabel('Amount of patients', fontsize=18, weight='bold')\n",
    "plt.title('Patient data samples', fontsize=32, weight='bold')\n",
    "plt.rc('xtick', labelsize=26) \n",
    "plt.rc('ytick', labelsize=12) \n",
    "plt.legend(fontsize=18)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long staying patients, check data collection interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat, count = np.unique(df_scrubb.PatientID, return_counts=True)\n",
    "print(f'Amount of patients with more than {MAX_LENGTH_OF_STAY} datapoints in total: {len(count[count > MAX_LENGTH_OF_STAY])}')\n",
    "\n",
    "df_long_stay = df_scrubb[np.isin(df_scrubb.PatientID, pat[count>MAX_LENGTH_OF_STAY])]\n",
    "\n",
    "\n",
    "for i, patID in enumerate(df_long_stay.PatientID.unique()):\n",
    "    df = df_long_stay[df_long_stay.PatientID==patID].copy()\n",
    "    time_in = min(df.Timestamp)\n",
    "    df.Timestamp = (df.Timestamp-time_in) /1000/3600/24\n",
    "    num_data = len(df)\n",
    "\n",
    "    y = np.ones(num_data)*i\n",
    "    plt.scatter(df.Timestamp, y, s=2)\n",
    "\n",
    "plt.xlabel('Days', fontsize=18)\n",
    "plt.ylabel('Patient', fontsize=18)\n",
    "plt.title('Timestamps for patients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check sample frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_frequency_list = []\n",
    "low_freq_pat_list = []\n",
    "high_freq_pat_list = []\n",
    "no_time_patID = []\n",
    "\n",
    "\n",
    "print(f'looping through {len(df_scrubb)} rows...')\n",
    "for i, patID in tqdm(enumerate(df_scrubb.PatientID.unique())):\n",
    "    df = df_scrubb[df_scrubb.PatientID==patID].copy()\n",
    "    time_in = min(df.Timestamp)\n",
    "    time_out = max(df.Timestamp)\n",
    "    time_spent = (time_out - time_in )/ (1000 * 3600 * 24)\n",
    "    if time_spent==0:\n",
    "        no_time_patID.append(patID)\n",
    "        continue  \n",
    "\n",
    "    sample_frequency = len(df)/ time_spent\n",
    "\n",
    "    if sample_frequency>HIGH_SAMPLE_FREQUENCY_LIMIT:\n",
    "        high_freq_pat_list.append((patID, sample_frequency))\n",
    "    elif sample_frequency<LOW_SAMPLE_FREQUENCY_LIMIT:\n",
    "        low_freq_pat_list.append((patID, sample_frequency))\n",
    "    \n",
    "    sample_frequency_list.append(sample_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of patients checked: {len(df_scrubb.PatientID.unique())}')\n",
    "print(f'Number of patients with no change in Timestamp: {len(no_time_patID)}')\n",
    "print(f'Number of patients with sample frequency over {HIGH_SAMPLE_FREQUENCY_LIMIT}: {len(high_freq_pat_list)}')\n",
    "print(f'Number of patients with sample frequency under {LOW_SAMPLE_FREQUENCY_LIMIT}: {len(low_freq_pat_list)}')\n",
    "\n",
    "_ = plt.hist(np.round(sample_frequency_list, 0), bins=50, log=True, label='Number of Patients')\n",
    "# Add vertical line\n",
    "vline_value = 4  # Value at which the vertical line should be placed\n",
    "plt.axvline(x=vline_value, color='red', linestyle='--', label='Optimal value')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Frequency', fontsize=18, weight='bold')\n",
    "plt.ylabel('#Patients Log scale', fontsize=18, weight='bold')\n",
    "plt.title('Sample frequency patients', fontsize=24, weight='bold')\n",
    "plt.rc('xtick', labelsize=14) \n",
    "plt.rc('ytick', labelsize=12) \n",
    "plt.legend(fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "_ = plt.hist(np.round(sample_frequency_list, 0), bins=50, log=False, label='Number of Patients')\n",
    "# Add vertical line\n",
    "vline_value = 4  # Value at which the vertical line should be placed\n",
    "plt.axvline(x=vline_value, color='red', linestyle='--', label='Optimal value')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Frequency', fontsize=18, weight='bold')\n",
    "plt.ylabel('#Patients', fontsize=18, weight='bold')\n",
    "plt.title('Sample frequency patients', fontsize=24, weight='bold')\n",
    "plt.rc('xtick', labelsize=14) \n",
    "plt.rc('ytick', labelsize=12) \n",
    "plt.legend(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('original data')\n",
    "display(np.sum(df_orig[df_orig.isna()], axis=0))\n",
    "print('scrubbed data')\n",
    "display(np.sum(df_scrubb[df_scrubb.isna()], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_DATA:\n",
    "    print(f\"saved the scrubbed data at: {SAVE_DATA_AS}\")\n",
    "    df_scrubb.to_csv(SAVE_DATA_AS, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
